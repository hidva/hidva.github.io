---
title: 编译器设计读书笔记
hidden: false
subtitle: "可能对你并没有什么用的"
tags: [读后感]
---

# 前言

编译器书籍选择。编译原理(龙书)，编译器设计(engineering a complier)。其中编译器设计更容易上手一点，更适合实践。编译原理更偏向于理论一点，更为全面。以 dfa 最小化算法举例，编译器设计首先介绍状态等价的概念，然后介绍了算法，很直观，但是有一些方面没有涉及介绍到。比如为啥初始集合中非终结状态，终结状态不能在一起？如下面例子，根据等价的定义B,C很显然等价嘛。

{% mermaid %}
graph LR
A-->|b|B
B-->|d|C
C-->|d|C
{% endmermaid %}

而编译原理则是从状态区分概念入手介绍了最小化算法，有理有据，不过感觉不那么直观。但是呢从区分概念入手最小化算法回答了上面的问题，因为接受状态和非接受状态是可区分的，所以不能放在一个集合中。

另外, 编译器设计知识面没有编译原理涉及到的广, 还是以上面最小化算法为例. 编译原理介绍了适用于词法分析器中的最小化算法. 而编译器设计则丝毫没有提起过, 这一度让我困惑了很久. 相关细节可以往下看.

# 第 1 章,  编译概观

这里讲述的东西大部分已经熟知, 所以这里只介绍一些概念相关的知识点.

语法; 程序语言语法通过某种规则的有限集定义了源语言集合; 这里语法规则是有限的, 而源语言集合是无限的. 词类, syntactic category, 又叫语法范畴, 语法规则中使用词类来引用单词, 这里词类是一堆具有公共特征的单词的总称, 比如 "标识符" 词类是所有可以作为标识符的单词的总称.词素, lexeme; 可以看为是词类的一个具体实例. 词类与语法单元, 按我理解在程序设计语言语法描述中, 词类是最小的, 不可再划分的粒度; 而语法单元则可以根据语法规则进一步划分, 直至划分为词类. 词法分析器扫描输入, 生成 '(单词所属词类, 单词具体值)' 流. 语法分析器扫描该流, 再根据语法来验证该流是否属于语法定义的源语言集合. microsyntax, 程序设计语言中用来描述词法结构的规则, microsyntax 定义了词类以及词类中单词的字符组合形式. 所以就能看出来了词法分析器根据 microsyntax 将字符流转换为单词流, 语法分析器根据语法验证单词流是否合法.

ILOC, intermediate language for an optimizing compiler, 可以看作某种简单的 RISC 机器的汇编语言. 参见原文了解 ILOC 语言的一些细节. 

编译期指令调度, 运行时指令调度; 很显然编译期指令调度由编译器完成, 运行时指令调度由 CPU 完成. 一直以来只是知道指令调度的存在, 但却不是很清楚指令调度的具体效果; 原来举了个例子展示了通过指令调度将性能提升一倍的案例, 可以了解一下.

# 第 2 章, 词法分析器

## 2.2 识别单词

还是先了解一些概念.

状态转移图, 起始状态, 接受状态. 再来看一些状态转移图的某些约定: 接受状态以双层圆圈绘制. 通常会省去目标为错误状态的转移, 因此识别器在遇到输入字符无法匹配到状态的某个转移时, 就转移到错误状态. 状态转移图中可以存在环, 来表明到自身的转移.

FA, 有限自动机, 其定义参考原文. 转移图是 FA 的形式化表示, FA 与转移图一一对应. 另外这里可能还有一个 "接受" 的概念, FA 接受字符串 x 的充分必要条件可以参考原文了解一下.

## 2.3 正则表达式

还是先介绍一些概念。这里的概念最好要摸清楚, 不然后面会很迷糊吃力.

语言，单词的集合. ~~这里单词可以认为是词素, 语言这个概念名感觉有点违和~~。FA 定义的语言记为 L(F)，即 FA 接受的字符串集合。

连接, 闭包, 选择; 定义于集合之上的操作, 或者说运算符, 注意这里操作数是集合, 数学中的那个集合. 运算符具体定义参考原文了解. 

正则表达式，正则表达式是一种符号表示法，描述了某个字母表 $$\sum$$ 上的字符串集合，即正则表达式也定义了一个语言, 记为 L(RE), 又称为正则语言。字母表 $$\sum$$ 上正则表达式集合的构造参见原文, 这里的构造方式定义了什么是正则表达式, 以及该正则表达式定义的语言(即字符串集合)是什么. 注意这里所使用的 '选择', '闭包', '连接' 是定义在正则表达式之上的运算符, 与上面定义在集合之上的同名运算符是两回事, 虽然两者很类似. 科学论证表明，FA 与正则表达式一一对应。

正则表达式运算符; 除了上述介绍的三种基本运算符之外, 正则表达式还支持其他运算符. 正闭包, 定义见原文. 有限闭包, 定义在原文. 求补^, 这个运算符原文没有精确地介绍, 按我理解, 对于 ^R 而言, 这里要求 $$L(R)$$ 的元素必须是字母表 $$\sum$$ 上的字母, 即 $$L(R)$$ 是 $$\sum$$ 的子集, L(^R) 等于字母表 $$\sum - L(R)$$.  求补~, ~~这个运算符原文并没有介绍就直接用了, 让我一度很困惑~~. 参考 wiki 百科定义, $$\sim R$$ 等于 $${\sum} ^ * - L(R)$$, 这里 $${\sum} ^ * $$ 表示 
$$
(a_1 | a_2 | ... | a_n) ^ *
$$, 其中$$\left \{ a_1, a_2,...,a_n  \right \} == \sum$$.  这里除了三种基本运算符之外的所有运算符都可以用三种基本运算符重写, 有限闭包, 正闭包这些显而易见, 对于求补~运算符, 按照 wiki 百科的说法也是可以重写的, 只是过程复杂了一些, ~~反正我是没有脑补出如何重写~~. 另外这里也可以看出正则表达式在三种基本运算符下是封闭的, 即将运算符应用到一个或一组正则表达式之上, 结果仍然是一个正则表达式.

正则表达式的运算符优先级; 首先 '()' 仍然具有最大的优先级, 其余依次是: '求补^', '闭包*', '连接', '选择'. 是的原文并没给出所有运算符的优先级, 我也没有办法.

字符范围表示, 定义参见原文, ~~这里为啥不用通用的 '[a-z]', 而是 '[a...z]' 呢?! 另外这里字符范围表示应该不能看作定义在正则表达式之上的运算符~~.

正则表达式 R 的补集 $$~R$$  对应的 FA; 这里记 R 对应的 FA 为 $$\left \{ S, \sum, \delta, s_0,S_A  \right \}$$; 则 $$~A$$ 对应的 FA 为 $$\left \{ S, \sum, \delta, s_0, S-S_A  \right \}$$, 即交换了原来 FA 的接受状态与非接受状态.

  
## 2.4 从正则表达式到词法分析器

构造法的循环，参见原文这张图，有点意思。

### 2.4.1 非确定性有限自动机

老规矩, 先看一下基本概念.

NFA, 非确定性有限自动机, DFA, 确定性有限自动机; 定义参见原文. NFA 对应的状态转移图通过引入$$\epsilon$$转移来表示这种不确定性, 以原文图那个用来识别 mn 的状态转移图举例, 当处在$$s_0$$状态, 遇到 m 时, 其可以转移到$$s_1$$, 也可以转移到$$s_2$$. 原文也提到了两个模型, 用来描述 NFA 的行为, 以期来让 NFA 的行为更具有确定性, ~~这里的模型2感觉就像多重宇宙理论中所说的当遇到不确定性事, 就派生出一个新的宇宙~~. 根据下文可知, 原文更倾向于使用模型 2 来描述 NFA 的行为.

NFA 的配置, 就是 NFA 状态的集合; 所以具有 n 个状态的 NFA 配置最多为 $$2^n$$, 即长度为 n 的集合的子集个数. 原文存在一个错误, 其认为配置总数是$$
{\left | \sum  \right |} ^ n
$$, [这里](https://cs.stackexchange.com/questions/80388/the-upper-bound-on-a-nondeterministic-finite-automatas-configurations-number)也有位仁兄看出来了. NFA 验证一个字符串是否被接受的过程也就是 NFA 从一个配置跳到另一个配置的过程, 还是以原文那个用来识别 mn 的状态转移图举例, 当其用来验证输入串 "mn" 时, 其会首先从配置$$\left \{ s_0 \right \}$$跳到$$\left \{ s_1, s_2 \right \}$$最后到$$\left \{ s_3 \right \}$$. 所以 NFA 接受一个字符串的充分必要条件是配置跳转路径中最后一个配置中存在至少一个终结状态. 这里还有个有效配置的概念: 即可以通过某个输入串到达的配置.

### 2.4.2 从正则表达式到 NFA: Thompson 构造法

Thompson 构造法大致流程: 首先为输入 RE 中每个字符构造简单的 NFA, 构造姿势参考原文; 然后按照正则表达式运算符的优先级, 将操作数对应的 NFA 按照运算符的语义转换为一个 NFA, 相当于将正则表达式运算符应用在一个或一组 NFA 上得到一个结果 NFA. 在此过程中, 始终遵循如下性质:

1.  每个构造出来的 NFA 都仅有一个起始状态, 都仅有一个接受状态; 不存在到起始状态的转移; 不存在从接受状态出发的转移.
2.  each state has at most two entering and two exiting $\epsilon$$moves, and at most one entering and one exiting move on a symbol in the alphabet. ~~原文对这句的翻译感觉怪怪的~~.
3.  在连接 NFA 时, 总是使用$$\epsilon$$转移将左操作数 NFA 的接受状态与右操作数 NFA 的起始状态连接在一起.

NFA 运算, 这里介绍一下如何将一个或一组 NFA 按照正则表达式运算符的语义转换为一个结果 NFA, 由上可知, 任何正则表达式运算符都可重写为三种基本运算符: 闭包, 连接, 选择, 所以这里只会介绍这三种 NFA 运算, 如下图所示:

![nfa op]({{site.url}}/assets/nfa.png)

### 2.4.3 从 NFA 到 DFA: 子集构造法

子集构造法, 参见原文了解其输入, 输出, 以及详细过程. 没什么难点, 可能是因为并没有让我们证明这时构造出来的 DFA 与原来的 NFA 接受相同的语言. 这里可以多琢磨琢磨为何循环能被终止, 而不会发生一直循环的情况.

离线计算 NFA 中每个状态的 $$\epsilon-closure$$; 这个算法初看有点绕. 其主要是利用{%raw%}$$\epsilon-closure(s) = \left \{ s \right \} U {\bigcup}_{{s\overset{\epsilon}{\rightarrow}p}\in \delta_N} \epsilon-closure(p)$${%endraw%}这个递推公式来构建的. 算法中用 E(s) 存放 $$\epsilon-closure(s)$$. worklist 是状态集合, 其内每一个状态 s 对应的 E(s) 等待着求解, 初始时 worklist 等于全部状态, 毕竟这时每一个状态都等待着求解 E(s). 然后对于 worklist 中每一个字符 s, 算法利用上面的递推公式根据目前 E 中保存的信息, 求解出 $$E_1(s)$$; 若 $$E_1(s) == E(s)$$ 则不需要更新 E. 否则使用 $$E_1(s)$$ 更新 E, 同时根据递推公式这时还需要更新哪些依赖着 E(s) 的状态 d 对应的 E(d), 即会把 d 再仍回 worklist 中.  再看一下为何这里的循环能终止, 由于 E(s) 只增不减, 然后$$\epsilon-closure(s)$$又是有限集合, 所以循环总会终止的, ~~可以多琢磨琢磨, 能严格证明就更好了~~.


### 2.4.4 从 DFA 到最小 DFA: Hopcroft 算法

状态等价, 等价的状态对于任何输入字符都将转移到已经等价的状态中. 可以将 DFA 中等价的状态当作一个状态来处理, 如下例子:

{% mermaid %}
graph LR
A-->|a|B
A-->|b|C
B-->|c|D
C-->|c|D
{% endmermaid %}

可以看到 B, C 是等价的, 所以可以将其作为一个状态来处理即如下 DFA 所示, 可以证明这里两个 DFA 接受相同的语言. 注意这里接受状态，非接受状态一定不会是等价的，即使它们看上去很相似，参见最上面前言中介绍。

{% mermaid %}
graph LR
E[B,C]
A-->|a|E
A-->|b|E
E-->|c|D
{% endmermaid %}

集合划分, hopcroft 中会用到这个概念, 定义参见原文. 

Hopcroft 算法; 就是利用等价的概念来最小化 DFA. 之所以这里叫 "最小化", 而不是 "小化", 是因为大佬们已经证明了 Hopcroft 算法生成的 DFA 就是接受相同语言前提下状态最小的 DFA 了.

Split 函数，在看 hopcroft 算法之前首先看下 split 函数。其输入是DFA状态集的子集S以及DFA状态集的一个集合划分T。位于T 中相同元素的两个状态可能是等价的。位于T中不同元素的两个状态一定是不等价的。split 输出是 S 的集合划分 Sout。同属于 Sout 同一个元素的状态可能是等价的。属于 Sout 中不同元素的状态一定是不等价的。Split 函数以伪代码的形式描述如下:

```
// ch 是 DFA 字母表某个字母。
Split(S, T, ch) {
    // m 是个 map, 其 key 是集合，取值可能是 T 中某个元素，也可能是空集。其 value 部分也是状态集合。
    m = {}  
    for s in S { 
        if exists move(s, ch) { 
            // T.get(s) 返回 T 中某个元素，其包括了状态 s。T 中必有一个元素而且仅有一个元素包括了 s。
            k = T.get(move(s, ch))
        } else { 
            k = {}  // 空集
        }
        m[k].append(s)
    }
    // 这里返回值符合上面对 Sout 的定义。
    return m.values()
}

Split(S,T) {
    // DFA.letters，DFA 字母表。
    for ch in DFA.letters {
         S1 = Split(S,T, ch)
         if len(S1) > 1 {
             return S1
         }
    }
    return {S}  // 只有一个元素 S 的集合。
}
```

Hopcroft 算法实现，参见原文。其中 Split 定义见上。之后根据集合 P 来构造新 DFA。把 P 中每一个元素都视为新 DFA 的状态。若 P 中元素包括了原 DFA 的初始状态，那么该元素对应新 DFA 的状态就是初始状态。若 P 中元素包括了原 DFA 的接受状态，那么该元素对应新 DFA 的状态就是接受状态。新 DFA 转换表的构建参见原文。

Hopcroft 算法循环可终止性分析，参见原文。

适用于词法分析器的 DFA 最小化算法，注意原来这里介绍的最小化并不适合词法分析器因为该算法会丢失掉一些信息，具体细节见下。



## 2.5 实现词法分析器

词法分析器的功能; ~~之前已经介绍了, 这里再说一次~~. 词法分析器的输入是表示源文件的字节流, 输出是 <语法范畴, 词素> 序列.

词法分析器的不同实现姿势; 原文给出了三种实现词法分析器的方式, 每个方式的具体细节下面会介绍. 值得注意的是三种实现方式效率的差别仅在于处理每个字符的常量成本, 而扫描的渐进复杂度是相同的, 均为 O(n), 其中 n 为输入串的长度. 下面依次介绍这三种姿势的词法分析器.

表驱动词法分析器对外提供的接口; 如下所示:

```c++
struct Lexer {
    Lexer(DFA *fa, Input *in);
    Token GetToken();
};
``` 

该接口期待用户的使用姿势是: 用户首先应该初始化一个 Lexer 实例, 传递相应的信息; 如上所示需要传递一个 DFA 实例, 表明待执行的 DFA; 以及输入流 in, Lexer 通过 in 来读取用户等待词法分析的源文件. 然后用户一直调用 GetToken(), 直至 GetToken() 返回 kEOF, 每次调用 GetToken() 都会返回下一个 <语法范畴, 词素> 组合.

表驱动词法分析器 v1.0 实现; 在 v1.0 中, Lexer 初始化逻辑很简单, 就是把 fa, in 保存下来供 GetToken() 调用时使用. 下面主要介绍 GetToken() 的实现, 如下以伪代码的形式介绍:

```c++
Token GetToken() {
    state = s0  // 当前状态
    lexeme = ""
    stack.clear()  // 状态栈, 用来记录本次 GetToken() 走过的状态用来回溯.    
    // 如下是每次循环开始都成立的不变量:
    // lexeme 记录了输入流 in 中已经读取到的字符, 即 lexeme + in 中未读取的字符 = 整个输入源文件.
    // stack 栈顶状态经由 lexeme 末尾字符转移会到达 state 所指的当前状态. 
    while (true) {  // 读取, 开始~
         if (state.IsAccept()) {
             // 遇到了一个接受状态, 在回溯时回溯到这个状态就足够了. 
             // 所以此时 stack 中记录的状态都不再重要了, 扔掉她们.
             stack.clear();  
         }
         ch = in.next()  // 输入流中下一个字符.
         if (ch == kEOF || !fa.ExistMove(state, ch)) {
             // 输入结束, 或者当前状态 state 不存在针对 ch 的转移.
             break         
         }
         stack.push(state)
         lexeme.append(ch) 
         state = fa.Move(state, ch)
    }
    // 此时表明识别遇到了问题, 可能需要回溯, 记得这时上面的不变量仍然成立.
    // 这里每次循环开始, 上面的不变量仍然也成立. 
    while (!state.IsAccept() && !stack.empty()) {   // 回溯, 开始~
        state = stack.pop();
        // 根据上面的不变量, 可以由 !stack.empty() 推断出 lexeme 也不为空.
        lexeme.pop_back();
        in.Rollback();  // in 回退一个位置.
    }
    if (!state.IsAccept()) {
        // 此时输入流 in 的状态与进入本次 GetToken() 调用时一致, 
        // in 的状态主要是包括 in 内部的读写指针这些. 
        return kErrorToken 
    }
    // 根据当前 state 对应的信息构造 Token 实例, 后面会讲到此时 state 中会存放着哪些信息.
    return Token(state, lexeme);
}
```

可以看出这里的 GetToken() 和原文有一些细节方面不太一致, 主要是引入了几个不变量可以帮助更好的理解执行流程. 另外原文的 truncate lexeme 会在 lexeme 为空时也执行, 我觉得应该是个 bug 了, ~~不信可以手动跑一下~~.

表驱动词法分析器 v2.0 实现. 在 v1.0 中, 某些案例会导致平方级别 $$O(n^2)$$ 的回滚(具体是指 in.Rollback() 这些)调用数目, 其中 n 为输入串长度. 如原文 $$
ab|(ab)^*c
$$ 例子, 这里以原文例子图中的 DFA, 输入串 "abababab" 作为 Lexer 初始化参数构造 Lexer 实例, 然后调用 GetToken(). 此时第一次调用会读取整个输入串, 然后回溯 6 次, 返回 "ab". 第 2 次调用也会读取完整个输入串, 然后回溯 4 次, 返回 "ab"... 更广义上讲, 假设输入串长度为 n, 那么最坏情况下, 回溯次数为 $$1 + 2 + 3 + ... + n = \frac{n * (n-1)}{2} \approx O(n^2)$$, ~~我自己瞎想出来的, 没证明过~~. 所以就有了 v2.0, v2.0 大体上是空间换时间的思路, 就是在每次 GetToken() 调用的回溯阶段记录下来哪些会进入死状态的转移, 然后在后续 GetToken() 调用中读取阶段, 如果发现当前转移已被记录是会走向死状态的, 那就终止读取立即开始回溯. 所以记录转移是否会走向死状态的信息是 Lexer 实例级别的, 每次 GetToken() 都是读写这部分信息. 现在就有一个问题, 如何来表(存)示(储)"该转移会进入死状态, 禁止通行"这种信息? 原文是通过 Failed 二维数组来表示的, 数组的行对应于 DFA 的每一个状态 s, 数组列对应于输入流中的位置 off, 就像 Linux 文件抽象一样, 文件就是一个字节数组, 其内每一个字节都有一个相对于文件开始的偏移量, Failed 数组列记录的就是这个偏移量. 所以输入流有多长, 就有多少数组列. 若 Failed[s][off] 取值为 true, 则表明在状态 s 上, 读取 off 指定位置的字符并进行的转移最终会走向死状态. 话说回来关于 Failed 数组, 我一开始纳闷为啥数组列记录的是输入流偏移. 而不是字母表中的字母 c, 表明在状态 s 执行字母 c 对应的转移最终会进入死状态. 后来意识到这时是否会进入死状态还与 c 后续的字母有关, 以下面的状态转移图举例, 从状态 A 开始, 若字母 c 后面跟着个字母 d, 那么是不会进入死状态的. 反之如果后面跟着个字母 e 那就会进入死状态了. 

{%mermaid%}
graph LR
A-->|c|B
B-->|d|D
{%endmermaid%}

在 v2.0 中初始化 Lexer 实例时, 除了 v1.0 的行为之外, 还需要根据 DFA 状态数以及输入流内容长度构建 Failed 二维数组, 并将其值全初始化为 false. 此时的 GetToken() 与 v1.0 版总体结构相差无异, 具体实现如下, 与 v1.0 版行为一致的地方将不再额外注释:

```c++
Token GetToken() {
    state = s0; 
    lexeme = '';
    // stack 中元素形式为 <state, off> 对应于 Failed 数组行与列. 
    stack.clear();
    pos = in.lseek();  // 获取输入流 in 当前偏移.
    // 此时的不变量除了 v1.0 中引入的之外, 还额外引入了:
    // pos 始终与 in.seek() 保持一致, 即 pos == in.seek() 总为 true.
    // stack 栈顶元素中 off 值就是 lexeme 末尾字符在输入流 in 中的偏移.
    // 根据这些不变量可以推断出:
    // pos == stack.back()[1] + 1, 即 pos 值等于 stack 栈顶元素 off 值 + 1.
    // stack 元素从栈底到栈顶, off 值始终以 1 递增.
    while (true) {
        if (state.IsAccept()) {
            stack.clear();
        }
        if (Failed[state][pos]) {
            // 在状态 state 读取 pos 处的字符并进行转移最终会进入死状态, 所以终止读取
            break ;
        }
        ch = in.next() 
        if (ch == kEOF) {
            break         
        }
        if (!fa.ExistMove(state, ch)) {
            in.Rollback();  // 为了保持 "pos == in.seek()" 这一不变量.
            break ;
        }
        stack.push(<state, pos>)
        lexeme.append(ch) 
        state = fa.Move(state, ch)
        ++pos
    }
    while (!state.IsAccept() && !stack.empty()) { 
        state, pos = stack.pop();
        Failed[state][pos] = true;  // 可以根据目前知识更新 Failed 了
        lexeme.pop_back();
    }
    // 并没有在回溯 while 循环中通过 in.Rollback() 回溯输入流, 主要是想着节省那么几次系统调用.
    // ~~在一个伪代码描述算法中, 至于整这些歪门邪道么~~.
    in.seek(pos);  
    if (!state.IsAccept()) {
        return kErrorToken 
    }
    return Token(state, lexeme);    
}    
```


直接编码的词法分析器, 也就是通过显式地 if...else... 或 switch...case... 也隐式表示 DFA, 具体操作姿势参见原文图2-16. 与上面的表驱动法相比, 直接编码更特化了一些. 我个人对这个没啥兴趣, 所以需要的同学可以直接去看原文.


手工编码的词法分析器; 与上面的直接编码相比, 手工编码更特化了一些, 比如在语法范畴仅表示一个词素时(就像关键词, 运算符们对应的语法范畴), 不再在 GetToken() 中返回 lexeme 部分. 而且更偏向于工程方面的优化, 比如引入输入流缓冲这些. 我个人对这个没啥兴趣, 所以需要的同学可以直接去看原文.

现实世界中的词法分析器如何编写; 因为词法分析器接受的输入是多个正则表达式, 所以词法分析器会将这些正则表达式通过选择运算符叠成一个正则表达式, 然后转换成 NFA, 这时可以做到根据 NFA 的接受状态确认此接受状态对应于输入中哪个或哪些正则; 然后利用子集构造法将 NFA 转 DFA, 这时 DFA 接受状态 x 可能对应于多个原 NFA 接受状态 y1,...,yn, 可以证明若某个输入串被 x 接受, 那么这个输入串也能被 y1,...,yn 接受. 然后最小化 DFA, 如果这时按照原文中的最小化算法, 那么当最小化 DFA 进入接受状态时, 无法根据这个状态得知当前 lexeme 究竟是被哪个正则表达式识别了, 只知道是被其中一个正则表达式识别了. 所以就不能照搬原文的最小化算法, 而且原文还很坑地没有介绍这种情况, 所幸编译原理介绍了这种情况以及如何处理. 参见编译原理 3.9.7 词法分析器的状态最小化章节. 利用这个最小化算法可以做到若最小化 DFA 接受状态对应着原 NFA 多个接受状态, 当最小化 DFA 接受了某个输入串, 可以证明对应着的多个原 NFA 接受状态同样会接受该字符串. 此时具体对应于哪个正则应该由用户来选择, 比如 lex 就遵循谁先出现选择谁.

## 2.6 高级主题

不感兴趣, 没深入了解, 有需要可以直接去看书~.


[To be continued...]

# 参考

编译器设计, 第2版.


