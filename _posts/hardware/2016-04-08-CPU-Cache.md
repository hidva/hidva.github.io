---
title: Cpu Cache 简单介绍
---

嗯,...,真的是很简单的介绍咯 @_@

## CPU Cache 为何引入

*   一张比较直观的时间图:

    -   execute typical instruction; 1 ns;
    -   L1 cache reference,从 L1 cache 中取数据; 0.5 ns 
    -   L2 cache reference,从 L2 cache 中取数据; 7 ns
    -   Main memory reference,从主存中取数据; 100 ns;

*   所以有必要引入 CPU Cache

## CPU Cache 实现

这里真是很简单的一点点内容 @_@

*   CPU Cache 模型;参考'MESI protocol'.
*   CPU Cache 如何工作;

    -   对于 CPU 而言,数据并没有类型,有无符号这些概念;对于 CPU 而言,这些都是一块一块的数据.
    -   在 CPU 需要读取主存上的数据时,其会把该数据周围数据(一般是 Cache line 大小,64 byte)先
        一同加载到 CPU Cache 中.这个应该是根据程序的局部性原理决定的.

*   Cache associativity;缓存关联性,指定了 CPU Cache 与 Memory 之间如何关联,如何映射.

*   Cache 一致性;参见'MESI protocol'协议.


## CPU Cache 友好的习惯

*   其实,我觉得这些亲近硬件的东西应该是编译器的锅,她应该根据源码行为以及目标平台然后生成缓存友好的
    代码.

### 避免 false sharing

*   false sharing 是啥? 先看下面一种情景:

    1.  内存中的数据是以 cache line 为单位从内存中读到 CPU cache 中的,比如有两个变量 X,Y;在
        内存中他们俩非常近,那么很有可能在读 X 的时候,Y 也被放到了相同 cache line 中.
    2.  Thread1 在一个循环中不停的写 X;Thread2 不停的写 Y;那么在 Thread1 写 X 的时候,需要
        Invalid 其他 cache 中对应的 cache line,Thread2 写 Y 的时候也要做同样的事情.
    
    这样就会碰到 MESI 中 2 个耗时的操作:
    
    -   写入到处于 Invalid 状态的 cache line.
    -   将一个 cache line 的状态更改为 Invalid.
    
*   如何解决 false sharing;很简单,增大 X,Y 之间的距离;确保 X,Y 不会被加载到同一 Cache line 
    中;在 Facebook/folly 项目中, X,Y 的距离是 128 byte!
    

## 参考

*   [高性能服务端系列 -- 处理器篇][0]
*   [Latency Numbers Every Programmer Should Know][1]


[0]: <http://zhuanlan.zhihu.com/p/20478552> 
[1]: <https://gist.github.com/jboner/2841832>


