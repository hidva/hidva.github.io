---
title: C/C++ 日常
tags: [开发经验, C++]
---


## SAX 风格的 json 解析姿势

SAX 对 json 解析库的要求是 json 库本身在 token-by-token 解析时遇到每一个 token 都应该以某种回调的方式通知到应用层. [Tencent/rapidjson](https://github.com/Tencent/rapidjson) 以及 PostgreSQL 内部的 json 库都支持这种方式. 以 rapidjson 为例, 其 SAX 解析定义了如下回调:

```c++
struct Handler {
    typename Ch;

    bool Null();
    bool Bool(bool b);
    bool Int(int i);
    bool Uint(unsigned i);
    bool Int64(int64_t i);
    bool Uint64(uint64_t i);
    bool Double(double d);
    /// enabled via kParseNumbersAsStringsFlag, string is not null-terminated (use length)
    bool RawNumber(const Ch* str, SizeType length, bool copy);
    bool String(const Ch* str, SizeType length, bool copy);
    bool StartObject();
    bool Key(const Ch* str, SizeType length, bool copy);
    bool EndObject(SizeType memberCount);
    bool StartArray();
    bool EndArray(SizeType elementCount);
};
```

应用自身需要实现各个回调, 来完成自身业务处理. 这里有个难点是应用自身在收到回调时, 看到的都是当前 token 的信息, 也即应用层需要维护额外的信息来知道这个 token 实际的语义. 在 ossjson 这个项目中, 我们通过把 json 视为一个树形结构, 即接受到的 token 都只是树中的一个节点, 之后通过在 handler 内部维护着一个隐式地从根节点到当前节点的 path, 从而得知了每次回调时, 当前 token 在树中的位置, 以及她的语义.


## 尽可能地重复利用对象

在 ossjson 这个项目中, 为了最大化降低不必要的负载, 我们会尽可能地重用对象. 以如下代码 demo 为例:

```c++
for (size_t i = 0; i < 3 * 100 * 10000; ++i) {
    rapidjson::Reader jreader;
    FillBuf(buf, json, jsonsize);
    rapidjson::InsituStringStream jinput(buf.data());
    Json2TupleHandler handler;

    jreader.IterativeParseInit();
    while (!jreader.IterativeParseComplete()) {
        if (!jreader.IterativeParseNext<kJsonParseFlags>(jinput, handler))
            throw std::runtime_error("error");
    }
}
```

将 `rapidjson::Reader jreader` 放在 for 循环之外, 以此来重复 jreader 对象, 会使得总耗时从 2.274s -> 0.415s.

对象的重用意味着在对象设计上, 我们应将对象的成员进行分层管理. 以 ossjson 中 Json2TupleHandler 为例, 便将其内部资源分为三层, 位于最底层的是与一个 tuple 相关的资源, 会在每次 ExecForeignScan 时被重置; 而中间层则是与一次 scan 相关的资源, 其会在 ExecReScanForeignScan 时被重置. 位于最上层的则是与一次 query 有关的资源, 其会在 ExecInitForeignScan 时被初始化, 在 ExecEndForeignScan 时被清除.

当类成员类型不固定的时候又该如何对资源进行分层呢, 如下以一个例子来展示. 在这个例子中, 我们需要读取位于 OSS 上的多个文件, 并且以行的形式向上返回, 也即需要提供如下类:

```c++
struct JsonInput {
    JsonInput(const std::vector<OssFile*> &files);
    char* TakeLine();
};
```

这里 `TakeLine()` 应感知文件边界这个事实. 即如果某个 oss 文件 a 最后一行未以 `\n` 结尾, 那么 JsonInput 不能把这一行与下一个文件第一行混在一起, 仍要把 a 最后一行单独返回. 考虑到用户在 OSS 的文件可能是以多种压缩格式共存的, 比如 gzip, snappy 等, 当然也可能是未压缩的文件. 因此很显然我们需要针对不同压缩格式的文件实现出不同的类:

```c++
struct PlainInputStream {
    size_t Read(void *buf, size_t size);
};

struct GzipInputStream {
    size_t Read(void *buf, size_t size);
};

struct SnappyInputStream {
    size_t Read(void *buf, size_t size);
};
```

之后 JsonInput 在这些类基础之上再加上 read line 的功能. 很显然为了实现简单, 以及向 JsonInput 暴露出文件边界这个存在, PlainInputStream/GzipInputStream 等都应该只需要支持单个文件的读取, 当遇到文件结尾时则返回 EOF. 那么 JsonInput 就需要为每一个文件单独构造出对应的 input stream. 这样也不是不可以, 毕竟常规情况下, JsonInput 的输入文件也不会有很多个. 但是我们还是想能不能尽量来复用对象从而降低可能的开销. 我最终的解决方案是, 每一个 InputStream 既然一次只需要支持一个文件的读取, 那么其内部可以将成员分为两类, 一类是初始化成本较高, 所以应该被尽量复用的资源. 一类是初始化成本很低, 不必要复用的资源. 每一个 InputStream 类都约定使用一个内部类 State 来存放着需要被复用的资源. 以 GzipInputStream 为例:

```c++
struct GzipInputStream {
    // State 存放着 GzipInputStream 中需要被复用的资源.
    // 其会在查询开始时 init, 在查询结束时 deinit.
	struct State {
		DISALLOW_COPY_MOVE(State);
        // 查询开始时调用, 初始化那些需要被复用的资源.
		State(XXXX *query_ctx):
			stat_(ofsstate)
		{
			DoInflateInit(&strm_);
			buffer_.reserve(gzip_buffer);
		}

        // 查询结束时调用, 释放所有资源.
		~State() noexcept
		{
			int ret = inflateEnd(&strm_);
			if (ret != Z_OK)
				elog(WARNING, "Fail to inflateEnd. ret=%d", ret);
		};
	private:
		z_stream strm_;
        // GzipInputStream 基于 PlainInputStream 实现, 所以
        // 应该包含 PlainInputStream 的 state.
		PlainInputStream::State stat_;
		std::vector<char> buffer_;
	};

    // 此时 file 指向着待读取的文件, 而 state 则存放着那些已被复用的资源.
    // state 内的资源都已经完成相应的初始化, 可直接被使用.
    GzipInputStream(OssFile *file, State *state):
        stream_(file, &state->stat_), stat_(state) {}

    // 当单个文件完成读取之后调用.
    // 这时已经重置 State 的某些资源
    ~OssFileGzipInputStream() noexcept
    {
		int ret = inflateReset(&stat_->strm_);
		if (ret != Z_OK)
            throw std::runtime_error("xxx")
    }

private:
    // 这里存放着初始化成本较低, 不值得复用的资源.
	PlainInputStream stream_;
	State *stat_;
	int zlibret_ {Z_OK};
};
```

之后 JsonInput 的实现便会直观了:

```c++
template <typename InputStream>
struct JsonInput {
    char* TakeLine()
    {
        if (!stream_) {
            // 上一个文件已经读取完毕, 使用下一个文件来初始化 input stream
            stream_ = std::make_unique<InputStream>(nextfile_, &stat_);
        }
        // read stream_
        if (read_eof_) {
            // 当前文件读取文件, 释放相关资源.
            stream_.reset();
        }
    }
private:
    std::unique<InputStream> stream_;
    typename InputStream::State stat_;
};
```

## virtual 与 template

如同 https://eli.thegreenplace.net/2013/12/05/the-cost-of-dynamic-virtual-calls-vs-static-crtp-dispatch-in-c 所示 virtual 与 template 的性能差异. 简单来说在可行的情况下 template 总是优于 virtual 了.

>   As expected, the CRTP approach is much faster. The benchmark above takes 1.25 seconds on my i7-4771 CPU for run_dynamic and 0.21 seconds for run_crtp This is a huge difference,

当然具体还要看自己的业务场景. 毕竟模板意味着代码体积的膨胀, 意味着指令 cache 命中率可能下降. 而且 template 也会导致代码阅读变差, 所以还是要规划好哪些参数走 virtual, 哪些走 CRTP. 以 ossjson 为例, 输入是否 linebreak, 以及输入采用的压缩方法则决定用 crtp 来实现, 其中 linebreak 与否函数实现差异所以拆分为两个函数. 而压缩方法则接口统一, 使用模板来降低重复开发. 如下 demo 展示了如何使用模板或者 virtual 来处理不同的压缩方法:

```c++
// 模板
struct GzipInputStream {
    int Read(void *buf, int length);
};

struct SnappyInputStream {
    int Read(void *buf, int length);
};

template <typename InputStream>
void DoSomething(InputStream *stream)
{
}

int main() {
    if (compress_method == "gzip")
        DoSomething(GzipInputStream());
    else
        DoSomething(SnappyInputStream());
}
```

```C++
// virtual
struct InputStream {
    virtual int Read(void *buf, int length) = 0;
};

struct GzipInputStream : public InputStream {
    int Read(void *buf, int length) override;
};

struct SnappyInputStream : public InputStream  {
    int Read(void *buf, int length) override;
}

void DoSomething(InputStream *stream)
{
}

int main() {
    InputStream *stream = nullptr;
    if (compress_method == "gzip")
        stream = new GzipInputStream();
    else
        stream = new SnappyInputStream();
    DoSomething(stream);
}
```


## C++11 线程原语在多进程中的表现

一句话, 尽量不要在多进程中使用 C++11 线程原语, 如 std::mutex 等, 哪怕 std::mutex 被放在共享内存中. 这种行为是 undefined 的. 我曾经无知地在 PG 中使用了 std::mutex, 然后结果很诡异. 所有 PG backend 都阻塞在 std::mutex::lock 中, 但是一旦尝试使用 gdb/strace 等命令 attach backend, 就会立刻从 lock 中返回, 感觉就很薛定谔... 这背后的原因可能是与信号处理函数中断了 futex 系统调用有关. 但具体并未深究, 毕竟是一个 UB.

另外 std::atomic 是可以放在共享内存中被多进程使用的. 毕竟这是 C++ specification 规定的:

>   [atomics.lockfree] includes "[Note: Operations that are lock-free should also be address-free. That is, atomic operations on the same memory location via two different addresses will communicate atomically. The implementation should not depend on any per-process state. This restriction enables communication by memory that is mapped into a process more than once and by memory that is shared between two processes. — end note ]".

## folly AsyncSocket 写出错时, WriteCallback 的行为

根据 folly AsyncSocket [源码](https://github.com/facebook/folly/blob/4cc8030e3bdc894c3979529e025c3160fd39ecd9/folly/io/async/AsyncSocket.cpp#L2266)可以看出 AsyncSocket 在写出错时会调用 WriteCallback, 并且在调用 write callback 之前会通过 startFail() 设置 `state_` 为 StateEnum::ERROR, 使得 write callback 内部调用的 closeNow() 变成一个 no-op 操作. 这与我本来假象的很不一样, 我本来以为当我在 write callback 内部调用 closeNow() 意味着此时会关闭当前 AsyncSocket, 之后在当前 writeCallback 返回时释放当前 AsyncSocket 所使用的一切资源, 即此后就不会有其他 callback 再在当前 AsyncSocket 实例上调用了. 所以你看, 能想象到我被坑地很惨!



## 总应该使用的编译选项

`-Wall -Wextra -Wno-unused -Wno-unused-parameter -Wshadow=global -Wshadow=local`

`-Wall -Wextra` 总应该使用, 其中输出的 warning 有时甚是重要, 尤其时变量未初始化使用, 我应该不止一次栽在这里, 譬如:

![惨]({{site.url}}/assets/valid.png)

`-Wshadow=global -Wshadow=local` 也总应该被使用. 我也栽在这个上面, 不小心在类成员函数内定义了与类成员同名的局部变量... 惨不忍睹!

关于 `-ggdb3` 与 `-O3` 的选择, 之前的我是倾向于 `-O3` 来试图拿下点性能提升的. 但是经过几次高压力 core debug 之后, 现在更倾向于 `-ggdb3` 了==! 话说回来了不是很懂 gcc 细节, `-ggdb3` 与 `-O3` 一起用的话是不是两全其美了?!

在开发阶段总应该使用的编译选项: 'CFLAGS=-O0 -fsanitize=address'. 曾经使用过 [address sanitize]({{site.url}}/2016/03/28/Address-Sanitizer/) 发现了 postgres-hll 存在的一处[内存越界存取](https://github.com/citusdata/postgresql-hll/pull/82), Greenplum 存在的一处 [heap-use-after-free](https://github.com/greenplum-db/gpdb/pull/8871).

## 总是应该使用单测来测试 movable 是否生效

参见 [总是尽量使用noexcpet]({{site.url}}/2016/03/23/总是尽量使用noexcpet/) 可以了解就算实现了移动构造/复制, 但 STL 可能并未调用移动语义, 这里的性能损失可是很不着痕迹不好排查啊! 更别说未显式实现移动语义的情况了, 如下代码:

```c++
#include <list>
#include <utility>
#include <iostream>

struct X {
    X() = default;
    X(const X&) {
        std::cout << __PRETTY_FUNCTION__ << std::endl;
    }
    X& operator=(const X&) {
        std::cout << __PRETTY_FUNCTION__ << std::endl;
    }
    X(X &&) {
        std::cout << __PRETTY_FUNCTION__ << std::endl;
    }
    X& operator=(X &&)  {
        std::cout << __PRETTY_FUNCTION__ << std::endl;
    }

    int i = 3;
};

struct Y {
    ~Y() noexcept {}

    Y() = default;
    // 注释改行, 下面 main() 将调用 X::X(const X&); 否则调用 X::X(X &&x).
    // 预期是总是调用 X::X(X&&).
    // Y(Y &&) = default;

    X x;
};

int main() {
    Y y;
    Y y2(std::move(y));
    std::list<Y> ys;
    Y y3(std::move(ys.front()));
    return 0;
}
```

总之, 我们应该总是根据类的特性显式定义拷贝构造, 拷贝复制, 移动构造, 移动复制函数; 可以借助于 `=delete` 或者 `=default`.


## 宏重载

额, 很 trick 的一个小特性, 主要是利用了宏的可变参数来实现, 如下 demo:

```c
#define _OSSJSON_GETARGS3(arg0, arg1, arg2) values, nulls, arg

#define _OSSJSON_GETARGS1(arg0) arg

#define _OSSJSON_GETMACRO_GETARGS(_1, _2, _3, NAME, ...) NAME

#define OSSJSON_GETARGS(...) _OSSJSON_GETMACRO_GETARGS(__VA_ARGS__, _OSSJSON_GETARGS3, TheMacroShouldNotExist, _OSSJSON_GETARGS1)(__VA_ARGS__)

```

此后 `OSSJSON_GETARGS(void *arg)` 与 `OSSJSON_GETARGS(Datum *values, bool *nulls, void *arg)` 将解析到不同的宏.
